
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>K-Nearest Neighbors</title><meta name="generator" content="MATLAB 7.14"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2014-01-26"><meta name="DC.source" content="knn_algorithm.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, tt, code { font-size:12px; }
pre { margin:0px 0px 20px; }
pre.error { color:red; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }

  </style></head><body><div class="content"><h1>K-Nearest Neighbors</h1><!--introduction--><p>Ejemplo de la implementaci&oacute;n del algoritmo de K-Vecinos m??s Cercanos</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#2">Datos</a></li><li><a href="#7">Variables</a></li><li><a href="#8">Distancia (Euclideana)</a></li><li><a href="#9">Distancias Ordenadas</a></li><li><a href="#10">K-Nearest Neighbors</a></li><li><a href="#12">Clasificaci??nn</a></li><li><a href="#13">Gr??ficas</a></li></ul></div><pre class="codeinput">clc
clear <span class="string">all</span>
</pre><h2>Datos<a name="2"></a></h2><p>Para la clasificaci?n por medio de los K-Vecinos m? Cercanos se necesitan los siguientes datos:</p><div><ul><li><b>Datos de entrenamiento</b>: Los datos conocidos previeamente</li><li><b>Clase de los datos de entrenamiento</b>: La clase a la que pertenece cada dato del conjunto de entrenamiento.</li><li><b>K</b>: N??mero de Vecinos m? Cercanos utilizados en la clasificaci??n.</li><li><b>Datos de prueba</b>: Los datos que se desean clasificar.</li></ul></div><p><b>Datos de Entrenamiento</b>. Se eligen 80 datos al azar para el conjunto de datos de entrenamiento</p><pre class="codeinput">nTrainData = 80;
trainData = rand(2,nTrainData);
</pre><p><b>Clases</b>. Para este ejemplo se eligieron colores (rojo, verde, azul, magenta) para representar las clases que se va clasificar. Para obtener el tipo de clase a la que pertenecen los datos del conjunto de prueba se obtienen aleatoriamente los valores de cada uno.</p><pre class="codeinput">colorClass = {<span class="string">'r'</span>,<span class="string">'g'</span>,<span class="string">'b'</span>,<span class="string">'m'</span>};
trainClass = randi(3,1,nTrainData); <span class="comment">% 80 n??meros entre 1 y 3</span>
</pre><p><b>Datos de Prueba</b>. Se eligien aleatoriamente los datos de prueba que ser calsificados</p><pre class="codeinput">nTestData = 5;
testData = rand(2,nTestData);
</pre><p><b>K</b>. K debe ser un n??mero entero positivo de valor menor o igual que el n??ero total de datos de entrenamiento.</p><pre class="codeinput">K = 3;
</pre><h2>Variables<a name="7"></a></h2><pre class="codeinput">[~, trainM]    = size(trainData);
[~, testM]     = size(testData);

distancias          = zeros(testM,trainM);
distanciasOrdenadas = zeros(testM,trainM);
</pre><h2>Distancia (Euclideana)<a name="8"></a></h2><p>Se calcula la distancia entre el punto de prueba y cada uno de los puntos del conjunto de entrenamiento por medio de la distancia euclideana.</p><pre class="codeinput"><span class="keyword">for</span> i=1:testM
    <span class="keyword">for</span> j=1:trainM;
     distancias(i,j) = pdist([trainData(:,j)'; testData(:,i)']);
    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><h2>Distancias Ordenadas<a name="9"></a></h2><p>Se ordenan todas las distancias de menor a mayor para obtener los puntos m??s cercanos. Se guarda tambi??n el lugar donde se encuentran los puntos m??s cercanos.</p><pre class="codeinput"><span class="keyword">for</span> i=1:testM
    [orden, ind] = sort(distancias(i,:));
    indice(i,:) = ind;
    distanciasOrdenadas(i,:) = orden;
<span class="keyword">end</span>
</pre><h2>K-Nearest Neighbors<a name="10"></a></h2><p>Se eligen ??nicamente los K-Vecinos m??s cercanos. Sus correspondientes clases por medio del ??ndice guardado anteriormente.</p><pre class="codeinput">indiceKNN = indice(:,1:K);
K_NN = zeros(2,K,testM);

<span class="keyword">for</span> i=1:testM
    <span class="keyword">for</span> j=1:K
        K_NN(:,j,i) = trainData(:,indiceKNN(i,j))';
    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><p>Se obtienen las clases que corresponden a cada uno de los K-Vecinos m??s cercanos encontrados anteriormente</p><pre class="codeinput">trainClass = trainClass';
testClassTemp = trainClass(indiceKNN);
</pre><h2>Clasificaci??nn<a name="12"></a></h2><p>Se calcula la clase que m??s se repite en el conjunto de K-clases de cada punto para determinar a qu?? clase pertenecen.</p><pre class="codeinput">Class = unique(testClassTemp);
nClass = length(Class);

<span class="keyword">for</span> i = 1:nClass
    contClass(i,:) = sum((testClassTemp == Class(i)),2); <span class="comment">% Filas</span>
<span class="keyword">end</span>

[~, indiceMax] = max(contClass);
testClass = Class(indiceMax);
</pre><h2>Gr??ficas<a name="13"></a></h2><p><b>Datos de Entrenamiento</b></p><pre class="codeinput">figure(1);
<span class="keyword">for</span> i=1:trainM
    A = trainData(:, i);
    trainPlot = plot(A(1,:), A(2,:),<span class="string">'o'</span>,<span class="keyword">...</span>
        <span class="string">'MarkerEdgeColor'</span>, <span class="string">'k'</span>,<span class="keyword">...</span>
        <span class="string">'MarkerFaceColor'</span>, colorClass{trainClass(i)},<span class="keyword">...</span>
        <span class="string">'MarkerSize'</span>, 7);
    hold <span class="string">on</span>;
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="knn_algorithm_01.png" alt=""> <p><b>Datos de Prueba</b>. Se grafican los datos de prueba sobre la gr??ica anterior, los 80 datos de prueba son representados por c??culos y los 5 datos de prueba por cuadrados.</p><pre class="codeinput"><span class="keyword">for</span> i=1:testM
    A = testData(:, i);
    testPlot = plot(A(1,:), A(2,:), <span class="string">'s'</span>,<span class="keyword">...</span>
        <span class="string">'LineWidth'</span>,2,<span class="keyword">...</span>
        <span class="string">'MarkerEdgeColor'</span>, <span class="string">'k'</span>,<span class="keyword">...</span>
        <span class="string">'MarkerFaceColor'</span>,colorClass{testClass(i)},<span class="keyword">...</span>
        <span class="string">'MarkerSize'</span>, 10);
    hold <span class="string">on</span>;
<span class="keyword">end</span>
legend([trainPlot, testPlot],<span class="string">'Train'</span>, <span class="string">'Test'</span>,<span class="keyword">...</span>
    <span class="string">'Location'</span>,<span class="string">'NorthEastOutside'</span>);
title(<span class="string">'K-Nearest Neighbors'</span>);
hold <span class="string">off</span>;
</pre><img vspace="5" hspace="5" src="knn_algorithm_02.png" alt=""> <p>En esta gr??ica los datos de prueba ya han sido clasificados y aparecen con el color correspondiende a su clase segun sus K-Vecinos m??s cercanos, en la siguietne gr??ica se visualizan de mejor forma estos puntos.</p><p><b>K-Vecinos m??s Cercanos</b> Se utiliza la funci??n <tt>patch</tt> para dibujar las distancias de los K-Vecinos m??s Cercanos.</p><pre class="codeinput"><span class="keyword">for</span> i=1:testM
    <span class="comment">% V??rtices</span>
    puntos(:,:,i) = [testData(:,i)'; K_NN(:,:,i)'];
    verts = puntos(:,:,i);
    <span class="comment">% Distancia</span>
    <span class="keyword">for</span> j=2:K+1
        dist = [1 j];

    <span class="comment">% Propiedades de patch</span>
    distancia.Vertices = verts;
    distancia.Faces = dist;
    distancia.FaceColor = <span class="string">'none'</span>;
    distancia.LineStyle = <span class="string">':'</span>;
    distancia.Edgecolor = <span class="string">'black'</span>;
    distancia.LineWidth = 1;

    patch(distancia);

    <span class="comment">% N??mero de cada punto de prueba</span>
    a = testData(:,i)';
    text(a(1)+0.03,a(2)+0.03, num2str(i));
    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><img vspace="5" hspace="5" src="knn_algorithm_03.png" alt=""> <p class="footer"><br>
      Published with MATLAB&reg; 7.14<br></p></div><!--
##### SOURCE BEGIN #####
%% K-Nearest Neighbors
% Ejemplo de la implementación del algoritmo de K-Vecinos más Cercanos
%
%%
clc
clear all
%% Datos
% Para la clasificación por medio de los K-Vecinos más Cercanos se
% necesitan los siguientes datos:
%
% * *Datos de entrenamiento*: Los datos conocidos previeamente
% * *Clase de los datos de entrenamiento*: La clase a la que pertenece cada
% dato del conjunto de entrenamiento.
% * *K*: Número de Vecinos más Cercanos utilizados en la clasificaci??n.
% * *Datos de prueba*: Los datos que se desean clasificar.

%%
% *Datos de Entrenamiento*. Se eligen 80 datos al azar para el conjunto de
% datos de entrenamiento
nTrainData = 80;
trainData = rand(2,nTrainData);

%%
% *Clases*. Para este ejemplo se eligieron colores (rojo, verde, azul, magenta) para
% representar las clases que se va clasificar. Para obtener el tipo de
% clase a la que pertenecen los datos del conjunto de prueba se obtienen
% aleatoriamente los valores de cada uno.
colorClass = {'r','g','b','m'};
trainClass = randi(3,1,nTrainData); % 80 números entre 1 y 3

%%
% *Datos de Prueba*. Se eligien aleatoriamente los datos de prueba que ser calsificados
nTestData = 5;
testData = rand(2,nTestData);

%%
% *K*. K debe ser un número entero positivo de valor menor o igual que el
% número total de datos de entrenamiento.
K = 3;

%% Variables
[~, trainM]    = size(trainData);
[~, testM]     = size(testData);

distancias          = zeros(testM,trainM);
distanciasOrdenadas = zeros(testM,trainM);



%% Distancia (Euclideana)
% Se calcula la distancia entre el punto de prueba y cada uno de los puntos
% del conjunto de entrenamiento por medio de la distancia euclideana.
for i=1:testM
    for j=1:trainM;
     distancias(i,j) = pdist([trainData(:,j)'; testData(:,i)']);
    end
end

%% Distancias Ordenadas
% Se ordenan todas las distancias de menor a mayor para obtener los
% puntos más cercanos. Se guarda también el lugar donde se encuentran los
% puntos más cercanos.
for i=1:testM
    [orden, ind] = sort(distancias(i,:));
    indice(i,:) = ind;
    distanciasOrdenadas(i,:) = orden;
end

%% K-Nearest Neighbors
% Se eligen únicamente los K-Vecinos más cercanos. Sus correspondientes
% clases por medio del índice guardado anteriormente.
indiceKNN = indice(:,1:K);
K_NN = zeros(2,K,testM);

for i=1:testM
    for j=1:K
        K_NN(:,j,i) = trainData(:,indiceKNN(i,j))';
    end
end

%%
% Se obtienen las clases que corresponden a cada uno de los K-Vecinos más
% cercanos encontrados anteriormente
trainClass = trainClass';
testClassTemp = trainClass(indiceKNN);

%% Clasificaciónn
% Se calcula la clase que más se repite en el conjunto de K-clases de cada
% punto para determinar a qué clase pertenecen.
Class = unique(testClassTemp);
nClass = length(Class);

for i = 1:nClass
    contClass(i,:) = sum((testClassTemp == Class(i)),2); % Filas
end

[~, indiceMax] = max(contClass);
testClass = Class(indiceMax);

%% Gráficas
%%
% *Datos de Entrenamiento*
figure(1);
for i=1:trainM
    A = trainData(:, i);
    trainPlot = plot(A(1,:), A(2,:),'o',...
        'MarkerEdgeColor', 'k',...
        'MarkerFaceColor', colorClass{trainClass(i)},...
        'MarkerSize', 7);
    hold on;
end

%%
% *Datos de Prueba*. Se grafican los datos de prueba sobre la gráica
% anterior, los 80 datos de prueba son representados por círculos y
% los 5 datos de prueba por cuadrados.
for i=1:testM
    A = testData(:, i);
    testPlot = plot(A(1,:), A(2,:), 's',...
        'LineWidth',2,...
        'MarkerEdgeColor', 'k',...
        'MarkerFaceColor',colorClass{testClass(i)},...
        'MarkerSize', 10);
    hold on;
end
legend([trainPlot, testPlot],'Train', 'Test',...
    'Location','NorthEastOutside');
title('K-Nearest Neighbors');
hold off;

%%
% En esta gráica los datos de prueba ya han sido clasificados y aparecen
% con el color correspondiende a su clase segun sus K-Vecinos más
% cercanos, en la siguietne gráica se visualizan de mejor forma estos
% puntos.

%%
% *K-Vecinos más Cercanos*
% Se utiliza la función |patch| para dibujar las distancias de los
% K-Vecinos más Cercanos.

for i=1:testM
    % Vértices
    puntos(:,:,i) = [testData(:,i)'; K_NN(:,:,i)'];
    verts = puntos(:,:,i);
    % Distancia
    for j=2:K+1
        dist = [1 j];

    % Propiedades de patch
    distancia.Vertices = verts;
    distancia.Faces = dist;
    distancia.FaceColor = 'none';
    distancia.LineStyle = ':';
    distancia.Edgecolor = 'black';
    distancia.LineWidth = 1;

    patch(distancia);

    % Número de cada punto de prueba
    a = testData(:,i)';
    text(a(1)+0.03,a(2)+0.03, num2str(i));
    end
end


##### SOURCE END #####
--></body></html>
